{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: '🔹 Paso 0: Preparación'\n",
        "jupyter: python3\n",
        "---"
      ],
      "id": "64632815"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "id": "9cda3baa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔹 Paso 1: Carga del Dataset\n"
      ],
      "id": "39465726"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reemplaza con tu archivo/dataset\n",
        "data = pd.read_csv(\"../1_data/dataset_obesity_clean.csv\", index_col=0)\n",
        "display(data.head())"
      ],
      "id": "064d0f4e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.columns"
      ],
      "id": "adfbd4e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔹 Paso 2: Preprocesamiento de Datos\n"
      ],
      "id": "23fb53c7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "categorical_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "categorical_cols.remove('NObeyesdad')\n",
        "data_encoded = pd.get_dummies(data, columns=categorical_cols, dummy_na=False) # cambia variables categoricas a numericas\n",
        "df_processed = data_encoded.copy()\n",
        "df_processed.head()"
      ],
      "id": "1c1df0c2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_processed.columns"
      ],
      "id": "7eaa5489",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔹 Paso 3: Ingeniería de Características\n"
      ],
      "id": "012b44da"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_processed['BMI'] = df_processed['Weight'] / (df_processed['Height'] ** 2)\n",
        "\n",
        "X = df_processed.drop(columns=['NObeyesdad'])\n",
        "y = df_processed['NObeyesdad']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "importances = rf_model.feature_importances_\n",
        "importance_df = pd.DataFrame({'feature': X_train.columns, 'importance': importances})\n",
        "importance_df.sort_values(by='importance', ascending=False).head(20)"
      ],
      "id": "f4352518",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔹 Paso 4: Nuevas Características Basadas en Importancia\n"
      ],
      "id": "43b44629"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_processed['Weight_Age_Ratio'] = df_processed['Weight'] / df_processed['Age']\n",
        "df_processed['FAF_TUE_Interaction'] = df_processed['FAF'] * df_processed['TUE']"
      ],
      "id": "b60e6eaf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔹 Paso 5: División del Dataset (Train/Val/Test)\n"
      ],
      "id": "0918283c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = df_processed.drop(columns=['NObeyesdad'])\n",
        "y = df_processed['NObeyesdad']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=84, stratify=y_temp)"
      ],
      "id": "5ace00d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔹 Paso 6: Escalamiento y Codificación\n"
      ],
      "id": "84038cf2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "numerical_cols = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE', 'BMI', 'Weight_Age_Ratio', 'FAF_TUE_Interaction']\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train[numerical_cols])\n",
        "X_val_scaled = scaler.transform(X_val[numerical_cols])\n",
        "X_test_scaled = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_train_encoded = encoder.fit_transform(y_train)\n",
        "y_val_encoded = encoder.transform(y_val)\n",
        "y_test_encoded = encoder.transform(y_test)\n",
        "\n",
        "train_df = pd.DataFrame(X_train_scaled, columns=numerical_cols)\n",
        "train_df['NObeyesdad'] = y_train_encoded\n",
        "val_df = pd.DataFrame(X_val_scaled, columns=numerical_cols)\n",
        "val_df['NObeyesdad'] = y_val_encoded\n",
        "test_df = pd.DataFrame(X_test_scaled, columns=numerical_cols)\n",
        "test_df['NObeyesdad'] = y_test_encoded"
      ],
      "id": "95721ff0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_df.columns"
      ],
      "id": "f6fc0f80",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔹 Paso 7: Entrenamiento y Evaluación de Modelos\n"
      ],
      "id": "16560eea"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "models = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
        "    \"SVM\": SVC(random_state=42),\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(train_df.drop(columns=['NObeyesdad']), train_df['NObeyesdad'])\n",
        "    y_pred_val = model.predict(val_df.drop(columns=['NObeyesdad']))\n",
        "    \n",
        "    results[name] = {\n",
        "        \"Accuracy\": accuracy_score(val_df['NObeyesdad'], y_pred_val),\n",
        "        \"Precision\": precision_score(val_df['NObeyesdad'], y_pred_val, average='weighted'),\n",
        "        \"Recall\": recall_score(val_df['NObeyesdad'], y_pred_val, average='weighted'),\n",
        "        \"F1-Score\": f1_score(val_df['NObeyesdad'], y_pred_val, average='weighted'),\n",
        "        \"Confusion Matrix\": confusion_matrix(val_df['NObeyesdad'], y_pred_val),\n",
        "    }\n",
        "\n",
        "    # Grafica la matriz de confusión de cada modelo\n",
        "    sns.heatmap(results[name][\"Confusion Matrix\"], annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
        "    plt.title(f\"{name} Confusion Matrix\")\n",
        "    plt.show()\n",
        "    \n",
        "    # Muestra la evaluación de cada modelo\n",
        "    print(f'{name}: ')\n",
        "    print(f'Accuracy: {results[name]['Accuracy']:.4f}')\n",
        "    print(f'Precision: {results[name]['Precision']:.4f}')\n",
        "    print(f'Recall: {results[name]['Recall']:.4f}')\n",
        "    print(f'F1-Score: {results[name]['F1-Score']:.4f}')\n",
        "    print('\\n\\n')\n"
      ],
      "id": "d8a2ae4e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔹 Paso 8: Tuning de Hiperparámetros (Random Forest)\n"
      ],
      "id": "7c4f7d11"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, scoring='accuracy', cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(train_df.drop(columns=['NObeyesdad']), train_df['NObeyesdad'])\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "print(\"Mejores hiperparámetros:\", grid_search.best_params_)"
      ],
      "id": "2c3b3311",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔹 Paso 9: Evaluación Final en Test Set\n"
      ],
      "id": "133c26e9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_pred_test = best_rf_model.predict(test_df.drop(columns=['NObeyesdad']))\n",
        "test_accuracy = accuracy_score(test_df['NObeyesdad'], y_pred_test)\n",
        "test_precision = precision_score(test_df['NObeyesdad'], y_pred_test, average='weighted')\n",
        "test_recall = recall_score(test_df['NObeyesdad'], y_pred_test, average='weighted')\n",
        "test_f1 = f1_score(test_df['NObeyesdad'], y_pred_test, average='weighted')\n",
        "\n",
        "\n",
        "test_confusion_matrix = confusion_matrix(test_df['NObeyesdad'], y_pred_test)\n",
        "\n",
        "\n",
        "sns.heatmap(test_confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Precision: {test_precision:.4f}\")\n",
        "print(f\"Recall: {test_recall:.4f}\")\n",
        "print(f\"F1-Score: {test_f1:.4f}\")"
      ],
      "id": "b9d9971b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "importances = best_rf_model.feature_importances_\n",
        "importance_df = pd.DataFrame({'feature': train_df.drop(columns=['NObeyesdad']).columns, 'importance': importances})\n",
        "importance_df.sort_values(by='importance', ascending=False).head(10)"
      ],
      "id": "72c05cca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import joblib\n",
        "joblib.dump(best_rf_model, 'modelo_rf.pkl') # Guarda el modelo de clasificacion\n",
        "joblib.dump(scaler, 'scaler.pkl') # Guarda el escalador de los datos numericos\n",
        "joblib.dump(encoder, 'encoder.pkl') # Guarda el codificador de las categorias de Obesidad"
      ],
      "id": "1127ac39",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import joblib\n",
        "import ollama  \n",
        "\n",
        "MODELO = 'mistral'\n",
        "\n",
        "# Cargar modelo de lenguaje local\n",
        "ollama.pull(MODELO)\n",
        "\n",
        "# Cargar modelo, scaler y encoder\n",
        "model = joblib.load(\"modelo_rf.pkl\")\n",
        "scaler = joblib.load(\"scaler.pkl\")\n",
        "encoder = joblib.load(\"encoder.pkl\")\n",
        "\n",
        "# Diccionario de traducción\n",
        "TRADUCCION_CLASES = {\n",
        "    \"Insufficient_Weight\": \"Peso insuficiente\",\n",
        "    \"Normal_Weight\": \"Peso normal\",\n",
        "    \"Overweight_Level_I\": \"Sobrepeso nivel I\",\n",
        "    \"Overweight_Level_II\": \"Sobrepeso nivel II\",\n",
        "    \"Obesity_Type_I\": \"Obesidad tipo I\",\n",
        "    \"Obesity_Type_II\": \"Obesidad tipo II\",\n",
        "    \"Obesity_Type_III\": \"Obesidad tipo III\"\n",
        "}\n",
        "\n",
        "# Función para generar el prompt para Ollama\n",
        "def generar_prompt(datos, clasificacion):\n",
        "    prompt = f\"\"\"\n",
        "Eres un asistente en nutrición y salud. El siguiente es el perfil de un paciente, incluyendo datos antropométricos y hábitos. Con base en esto, proporciona:\n",
        "1. Un análisis breve de su estado de salud.\n",
        "2. Una recomendación personalizada para mejorar su salud.\n",
        "3. Consejos adaptados a su estilo de vida.\n",
        "\n",
        "Datos del paciente:\n",
        "- Edad: {datos['Age']} años\n",
        "- Estatura: {datos['Height']} m\n",
        "- Peso: {datos['Weight']} kg\n",
        "- Frecuencia de consumo de vegetales (FCVC) de 0-3: {datos['FCVC']}\n",
        "- Número de comidas diarias (NCP): {datos['NCP']}\n",
        "- Consumo diario de agua (CH2O) de 0-3: {datos['CH2O']}\n",
        "- Nivel de actividad física (FAF) de 0-3: {datos['FAF']}\n",
        "- Horas frente a pantallas (TUE) de 0-2: {datos['TUE']}\n",
        "\n",
        "Resultado del modelo de clasificación: **{clasificacion}**\n",
        "\n",
        "Sé empático, claro y usa lenguaje sencillo. Utiliza lenguaje español latino en todo momento. Escribe la recomendación en tercera persona.\n",
        "\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "# Función principal\n",
        "def predecir_obesidad(Age, Height, Weight, FCVC, NCP, CH2O, FAF, TUE):\n",
        "    # Variables derivadas\n",
        "    BMI = Weight / (Height ** 2)\n",
        "    Weight_Age_Ratio = Weight / Age\n",
        "    FAF_TUE_Interaction = FAF * TUE\n",
        "\n",
        "    # Preprocesamiento\n",
        "    features = np.array([[Age, Height, Weight, FCVC, NCP, CH2O, FAF, TUE,\n",
        "                          BMI, Weight_Age_Ratio, FAF_TUE_Interaction]])\n",
        "    features_scaled = scaler.transform(features)\n",
        "\n",
        "    # Predicción\n",
        "    prediction = model.predict(features_scaled)\n",
        "    clase = encoder.inverse_transform(prediction)[0]\n",
        "    clase_es = TRADUCCION_CLASES.get(clase, \"Clasificación desconocida\")\n",
        "\n",
        "    # Generar prompt para LLM\n",
        "    datos_usuario = {\n",
        "        \"Age\": Age, \"Height\": Height, \"Weight\": Weight,\n",
        "        \"FCVC\": FCVC, \"NCP\": NCP, \"CH2O\": CH2O,\n",
        "        \"FAF\": FAF, \"TUE\": TUE\n",
        "    }\n",
        "    prompt = generar_prompt(datos_usuario, clase_es)\n",
        "\n",
        "    # Llamar al modelo local con Ollama\n",
        "    respuesta_llm = ollama.chat(\n",
        "        model=MODELO,  # puedes usar \"llama2\" o el modelo que tengas disponible\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )[\"message\"][\"content\"]\n",
        "\n",
        "    # Retornar clasificación + recomendación\n",
        "    resultado = f\"📊 Clasificación: {clase_es}\\n\\n🧠 Recomendación personalizada:\\n{respuesta_llm}\"\n",
        "    return resultado\n",
        "\n",
        "# Interfaz Gradio\n",
        "interface = gr.Interface(\n",
        "    fn=predecir_obesidad,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Edad\"),\n",
        "        gr.Number(label=\"Estatura (m)\"),\n",
        "        gr.Number(label=\"Peso (kg)\"),\n",
        "        gr.Slider(1, 3, step=0.1, label=\"Frecuencia de consumo de vegetales (FCVC)\"),\n",
        "        gr.Slider(1, 4, step=1, label=\"Número de comidas (NCP)\"),\n",
        "        gr.Slider(1, 3, step=0.1, label=\"Consumo de agua (CH2O)\"),\n",
        "        gr.Slider(0, 3, step=0.1, label=\"Actividad física (FAF)\"),\n",
        "        gr.Slider(0, 2, step=0.1, label=\"Uso de tecnología (TUE)\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"Clasificador de Obesidad con Recomendación Personalizada\",\n",
        "    description=\"Ingresa tus datos para obtener tu clasificación de obesidad y una recomendación personalizada.\"\n",
        ")\n",
        "\n",
        "interface.launch(share=True) # share=True genera un enlace para compartir"
      ],
      "id": "f68831ba",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Library/Frameworks/Python.framework/Versions/3.13/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}